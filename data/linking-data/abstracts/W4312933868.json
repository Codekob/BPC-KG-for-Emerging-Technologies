{"By": [0, 126], "decomposing": [1], "the": [2, 35, 87, 108, 131, 171], "image": [3, 21, 36, 175, 179, 190], "formation": [4], "process": [5, 38], "into": [6, 130, 138], "a": [7, 30, 104, 113, 159], "sequential": [8, 67], "application": [9], "of": [10, 52, 58, 90, 170], "denoising": [11], "autoencoders,": [12], "diffusion": [13, 100, 136, 164], "models": [14, 44, 101, 137, 165], "(DMs)": [15], "achieve": [16, 167], "state-of-the-art": [17], "synthesis": [18, 155, 180], "results": [19], "on": [20, 73, 102, 185], "data": [22], "and": [23, 61, 81, 119, 140, 153, 177, 181, 194], "beyond.": [24], "Additionally,": [25], "their": [26, 79], "formulation": [27], "allows": [28, 106], "for": [29, 107, 143, 174], "guiding": [31], "mechanism": [32], "to": [33, 66, 96, 111, 202], "control": [34], "generation": [37], "without": [39], "retraining.": [40], "However,": [41], "since": [42], "these": [43], "typically": [45], "operate": [46], "directly": [47], "in": [48, 86, 158], "pixel": [49], "space,": [50], "optimization": [51], "powerful": [53, 91, 139], "DMs": [54], "often": [55], "consumes": [56], "hundreds": [57], "GPU": [59], "days": [60], "inference": [62], "is": [63], "expensive": [64], "due": [65], "evaluations.": [68], "To": [69], "enable": [70], "DM": [71], "training": [72, 99], "limited": [74], "computational": [75, 199], "resources": [76], "while": [77, 196], "retaining": [78], "quality": [80], "flexibility,": [82], "we": [83, 134], "apply": [84], "them": [85], "latent": [88, 163], "space": [89], "pretrained": [92], "autoencoders.": [93], "In": [94], "contrast": [95], "previous": [97], "work,": [98], "such": [103, 147], "representation": [105], "first": [109], "time": [110], "reach": [112], "near-optimal": [114], "point": [115], "between": [116], "complexity": [117], "reduction": [118], "detail": [120], "preservation,": [121], "greatly": [122], "boosting": [123], "visual": [124], "fidelity.": [125], "introducing": [127], "cross-attention": [128], "layers": [129], "model": [132], "architecture,": [133], "turn": [135], "flexible": [141], "generators": [142], "general": [144], "conditioning": [145], "inputs": [146], "as": [148], "text": [149], "or": [150], "bounding": [151], "boxes": [152], "high-resolution": [154], "becomes": [156], "possible": [157], "convolutional": [160], "manner.": [161], "Our": [162], "(LDMs)": [166], "new": [168], "state": [169], "art": [172], "scores": [173], "inpainting": [176], "class-conditional": [178], "highly": [182], "competitive": [183], "performance": [184], "various": [186], "tasks,": [187], "including": [188], "unconditional": [189], "generation,": [191], "text-to-image": [192], "synthesis,": [193], "super-resolution,": [195], "significantly": [197], "reducing": [198], "requirements": [200], "compared": [201], "pixel-based": [203], "DMs.": [204]}