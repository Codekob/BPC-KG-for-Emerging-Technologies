{"Groundbreaking": [0], "language-vision": [1, 60], "architectures": [2], "like": [3, 62, 143], "CLIP": [4], "and": [5, 42, 67, 75, 108, 138, 146, 152, 178, 181, 187], "DALL-E": [6], "proved": [7], "the": [8, 73, 100, 150], "utility": [9], "of": [10, 15, 37, 77, 84, 91, 122, 128, 140, 162], "training": [11, 74], "on": [12, 21, 111], "large": [13], "amounts": [14], "noisy": [16], "image-text": [17, 85, 126], "data,": [18], "without": [19], "relying": [20], "expensive": [22], "accurate": [23], "labels": [24], "used": [25], "in": [26], "standard": [27], "vision": [28], "unimodal": [29], "supervised": [30], "learning.": [31], "The": [32], "resulting": [33], "models": [34, 61, 79, 142], "showed": [35], "capabilities": [36, 76], "strong": [38], "text-guided": [39], "image": [40], "generation": [41], "transfer": [43], "to": [44], "downstream": [45], "tasks,": [46], "while": [47], "performing": [48], "remarkably": [49], "at": [50], "zero-shot": [51], "classification": [52], "with": [53, 157], "noteworthy": [54], "out-of-distribution": [55], "robustness.": [56], "Since": [57], "then,": [58], "large-scale": [59, 112], "ALIGN,": [63], "BASIC,": [64], "GLIDE,": [65], "Flamingo": [66], "Imagen": [68], "made": [69, 96], "further": [70, 154], "improvements.": [71], "Studying": [72], "such": [78], "requires": [80], "datasets": [81, 90], "containing": [82], "billions": [83], "pairs.": [86], "Until": [87], "now,": [88], "no": [89], "this": [92, 106, 163], "size": [93], "have": [94], "been": [95], "openly": [97, 159], "available": [98, 160], "for": [99, 175, 184], "broader": [101], "research": [102, 110], "community.": [103], "To": [104], "address": [105], "problem": [107], "democratize": [109], "multi-modal": [113], "models,": [114], "we": [115, 166], "present": [116], "LAION-5B": [117], "-": [118], "a": [119], "dataset": [120, 161, 176], "consisting": [121], "5.85": [123], "billion": [124], "CLIP-filtered": [125], "pairs,": [127], "which": [129], "2.32B": [130], "contain": [131], "English": [132], "language.": [133], "We": [134], "show": [135], "successful": [136], "replication": [137], "fine-tuning": [139], "foundational": [141], "CLIP,": [144], "GLIDE": [145], "Stable": [147], "Diffusion": [148], "using": [149], "dataset,": [151], "discuss": [153], "experiments": [155], "enabled": [156], "an": [158, 172], "scale.": [164], "Additionally": [165], "provide": [167], "several": [168], "nearest": [169], "neighbor": [170], "indices,": [171], "improved": [173], "web-interface": [174], "exploration": [177], "subset": [179], "generation,": [180], "detection": [182], "scores": [183], "watermark,": [185], "NSFW,": [186], "toxic": [188], "content": [189], "detection.": [190], "Announcement": [191], "page": [192], "https://laion.ai/laion-5b-a-new-era-of-open-large-scale-multi-modal-datasets/": [193]}