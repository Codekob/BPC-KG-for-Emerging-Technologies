{"Automatic": [0], "medical": [1, 66, 127, 211], "image": [2, 67, 212], "segmentation": [3, 68, 123, 213], "has": [4], "made": [5], "great": [6], "progress": [7], "owing": [8], "to": [9, 28, 78, 151, 173, 193], "the": [10, 17, 30, 39, 44, 50, 80, 90, 98, 105, 113, 121, 134, 153, 176, 181, 187, 196, 201, 215, 224], "powerful": [11], "deep": [12, 65], "representation": [13], "learning.": [14], "Inspired": [15], "by": [16], "success": [18], "of": [19, 33, 89, 125, 159, 217], "self-attention": [20, 99, 182], "mechanism": [21, 142], "in": [22, 43, 101], "Transformer,": [23], "considerable": [24], "efforts": [25], "are": [26], "devoted": [27], "designing": [29], "robust": [31], "variants": [32], "encoder-decoder": [34], "architecture": [35], "with": [36], "Transformer.": [37], "However,": [38], "patch": [40], "division": [41], "used": [42], "existing": [45], "Transformer-based": [46, 132], "models": [47], "usually": [48], "ignores": [49], "pixel-level": [51], "intrinsic": [52], "structural": [53], "features": [54], "inside": [55], "each": [56], "patch.": [57], "In": [58], "this": [59], "paper,": [60], "we": [61, 185], "propose": [62], "a": [63, 138, 164], "novel": [64], "framework": [69], "called": [70], "Dual": [71], "Swin": [72, 82, 102, 149, 188], "Transformer": [73, 83, 103, 150, 166, 189], "U-Net": [74], "(DS-TransUNet),": [75], "which": [76, 109], "aims": [77], "incorporate": [79], "hierarchical": [81], "into": [84, 191], "both": [85], "encoder": [86], "and": [87, 104, 116, 155, 219], "decoder": [88, 192], "standard": [91], "U-shaped": [92], "architecture.": [93], "Our": [94], "DS-TransUNet": [95, 136], "benefits": [96], "from": [97], "computation": [100], "designed": [106], "dual-scale": [107, 140, 145], "encoding,": [108], "can": [110], "effectively": [111, 174], "model": [112], "non-local": [114], "dependencies": [115], "multi-scale": [117, 177], "contexts": [118], "for": [119, 210], "enhancing": [120], "semantic": [122, 161], "quality": [124], "varying": [126], "images.": [128], "Unlike": [129], "many": [130], "prior": [131], "solutions,": [133], "proposed": [135, 172], "adopts": [137], "well-established": [139], "encoding": [141], "that": [143], "utilizes": [144], "encoders": [146], "based": [147], "on": [148], "extract": [152], "coarse": [154], "fine-grained": [156], "feature": [157], "representations": [158], "different": [160], "scales.": [162], "Meanwhile,": [163], "well-designed": [165], "Interactive": [167], "Fusion": [168], "(TIF)": [169], "module": [170], "is": [171], "perform": [175], "information": [178, 199], "fusion": [179], "through": [180], "mechanism.": [183], "Furthermore,": [184], "introduce": [186], "block": [190], "further": [194], "explore": [195], "long-range": [197], "contextual": [198], "during": [200], "up-sampling": [202], "process.": [203], "Extensive": [204], "experiments": [205], "across": [206], "four": [207], "typical": [208], "tasks": [209], "demonstrate": [214], "effectiveness": [216], "DS-TransUNet,": [218], "our": [220], "approach": [221], "significantly": [222], "outperforms": [223], "state-of-the-art": [225], "methods.": [226]}