{"Abstract": [0], "Pretrained": [1], "neural": [2], "network": [3], "models": [4, 19, 63, 80, 103], "for": [5, 13, 37, 70], "biological": [6], "segmentation": [7, 27], "can": [8, 34, 86], "provide": [9, 130], "good": [10], "out-of-the-box": [11], "results": [12], "many": [14], "image": [15], "types.": [16], "However,": [17], "such": [18, 133], "do": [20], "not": [21], "allow": [22], "users": [23], "to": [24, 29, 97, 110, 122, 147], "adapt": [25], "the": [26, 45, 83, 118, 149], "style": [28], "their": [30], "specific": [31], "needs": [32], "and": [33, 143], "perform": [35, 98], "suboptimally": [36], "test": [38], "images": [39], "that": [40, 56, 79], "are": [41], "very": [42], "different": [43], "from": [44], "training": [46], "images.": [47], "Here": [48], "we": [49], "introduce": [50], "Cellpose": [51, 84, 152], "2.0,": [52], "a": [53, 67, 140, 144], "new": [54, 74], "package": [55], "includes": [57], "an": [58, 135], "ensemble": [59], "of": [60, 73, 94, 151], "diverse": [61], "pretrained": [62, 81], "as": [64, 66, 100, 102, 134], "well": [65, 101], "human-in-the-loop": [68, 114, 145], "pipeline": [69, 146], "rapid": [71], "prototyping": [72], "custom": [75], "models.": [76], "We": [77, 129], "show": [78], "on": [82, 105], "dataset": [85], "be": [87], "fine-tuned": [88], "with": [89, 108], "only": [90], "500\u20131,000": [91], "user-annotated": [92], "regions": [93], "interest": [95], "(ROI)": [96], "nearly": [99], "trained": [104], "entire": [106], "datasets": [107], "up": [109], "200,000": [111], "ROI.": [112], "A": [113], "approach": [115], "further": [116], "reduced": [117], "required": [119], "user": [120, 138], "annotation": [121, 136], "100\u2013200": [123], "ROI,": [124], "while": [125], "maintaining": [126], "high-quality": [127], "segmentations.": [128], "software": [131], "tools": [132], "graphical": [137], "interface,": [139], "model": [141], "zoo": [142], "facilitate": [148], "adoption": [150], "2.0.": [153]}