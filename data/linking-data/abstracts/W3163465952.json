{"We": [0, 69, 100], "present": [1], "ResMLP,": [2], "an": [3], "architecture": [4], "built": [5], "entirely": [6], "upon": [7], "multi-layer": [8], "perceptrons": [9], "for": [10], "image": [11, 27], "classification.": [12], "It": [13], "is": [14], "a": [15, 22, 37, 51, 75, 84], "simple": [16], "residual": [17], "network": [18, 40], "that": [19], "alternates": [20], "(i)": [21], "linear": [23], "layer": [24], "in": [25, 41, 74], "which": [26, 42], "patches": [28], "interact,": [29], "independently": [30, 45], "and": [31, 35, 58, 104], "identically": [32], "across": [33], "channels,": [34], "(ii)": [36], "two-layer": [38], "feed-forward": [39], "channels": [43], "interact": [44], "per": [46], "patch.": [47], "When": [48], "trained": [49], "with": [50], "modern": [52], "training": [53], "strategy": [54], "using": [55], "heavy": [56], "data-augmentation": [57], "optionally": [59], "distillation,": [60], "it": [61], "attains": [62], "surprisingly": [63, 97], "good": [64, 98], "accuracy/complexity": [65], "trade-offs": [66], "on": [67, 108], "ImageNet.": [68], "also": [70], "train": [71], "ResMLP": [72], "models": [73, 103], "self-supervised": [76], "setup,": [77], "to": [78, 92], "further": [79], "remove": [80], "priors": [81], "from": [82], "employing": [83], "labelled": [85], "dataset.": [86], "Finally,": [87], "by": [88], "adapting": [89], "our": [90, 105], "model": [91], "machine": [93], "translation": [94], "we": [95], "achieve": [96], "results.": [99], "share": [101], "pre-trained": [102], "code": [106], "based": [107], "the": [109], "Timm": [110], "library.": [111]}