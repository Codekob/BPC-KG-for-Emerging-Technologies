{"Large": [0], "language": [1, 21, 59, 77], "models": [2, 135], "(LLMs)": [3], "have": [4, 26], "been": [5], "shown": [6], "to": [7, 10, 28, 65], "be": [8], "able": [9], "perform": [11], "new": [12], "tasks": [13], "based": [14], "on": [15, 82, 109], "a": [16, 46, 56, 66, 74, 86, 110], "few": [17], "demonstrations": [18], "or": [19], "natural": [20, 94], "instructions.": [22], "While": [23], "these": [24], "capabilities": [25], "led": [27], "widespread": [29], "adoption,": [30], "most": [31], "LLMs": [32], "are": [33, 39], "developed": [34], "by": [35], "resource-rich": [36], "organizations": [37], "and": [38, 62, 95, 127, 136], "frequently": [40], "kept": [41], "from": [42], "the": [43, 83, 139], "public.": [44], "As": [45], "step": [47], "towards": [48], "democratizing": [49], "this": [50], "powerful": [51], "technology,": [52], "we": [53, 131], "present": [54], "BLOOM,": [55], "176B-parameter": [57], "open-access": [58], "model": [60, 78], "designed": [61], "built": [63], "thanks": [64], "collaboration": [67], "of": [68, 70, 90, 113], "hundreds": [69, 89], "researchers.": [71], "BLOOM": [72, 105], "is": [73], "decoder-only": [75], "Transformer": [76], "that": [79, 104], "was": [80], "trained": [81], "ROOTS": [84], "corpus,": [85], "dataset": [87], "comprising": [88], "sources": [91], "in": [92, 100], "46": [93], "13": [96], "programming": [97], "languages": [98], "(59": [99], "total).": [101], "We": [102], "find": [103], "achieves": [106], "competitive": [107], "performance": [108], "wide": [111], "variety": [112], "benchmarks,": [114], "with": [115], "stronger": [116], "results": [117], "after": [118], "undergoing": [119], "multitask": [120], "prompted": [121], "finetuning.": [122], "To": [123], "facilitate": [124], "future": [125], "research": [126], "applications": [128], "using": [129], "LLMs,": [130], "publicly": [132], "release": [133], "our": [134], "code": [137], "under": [138], "Responsible": [140], "AI": [141], "License.": [142]}