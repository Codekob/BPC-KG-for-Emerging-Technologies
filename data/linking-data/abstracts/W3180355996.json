{"Designed": [0], "to": [1, 10, 22, 67, 77, 81, 95, 108], "learn": [2, 82], "long-range": [3], "interactions": [4], "on": [5, 14, 138], "sequential": [6], "data,": [7], "transformers": [8, 64, 94], "continue": [9], "show": [11, 75], "state-of-the-art": [12], "results": [13, 137], "a": [15, 83], "wide": [16], "variety": [17], "of": [18, 54, 58, 63, 86, 141], "tasks.": [19], "In": [20, 131], "contrast": [21], "CNNs,": [23], "they": [24], "contain": [25], "no": [26], "inductive": [27, 56], "bias": [28, 57], "that": [29], "prioritizes": [30], "local": [31], "interactions.": [32], "This": [33], "makes": [34], "them": [35, 66], "expressive,": [36], "but": [37], "also": [38], "computationally": [39], "infeasible": [40], "for": [41], "long": [42], "sequences,": [43], "such": [44, 116, 123], "as": [45, 117, 124], "high-resolution": [46, 72, 101], "images.": [47, 73, 102], "We": [48, 74], "demonstrate": [49], "how": [50, 76], "combining": [51], "the": [52, 55, 61, 128, 135], "effectiveness": [53], "CNNs": [59, 80], "with": [60, 144], "expressivity": [62], "enables": [65], "model": [68, 97], "and": [69, 89, 120], "thereby": [70], "synthesize": [71], "(i)": [78], "use": [79], "context-rich": [84], "vocabulary": [85], "image": [87], "constituents,": [88], "in": [90], "turn": [91], "(ii)": [92], "utilize": [93], "efficiently": [96], "their": [98], "composition": [99], "within": [100], "Our": [103], "approach": [104], "is": [105], "readily": [106], "applied": [107], "conditional": [109], "synthesis": [110, 140], "tasks,": [111], "where": [112], "both": [113], "non-spatial": [114], "information,": [115, 122], "object": [118], "classes,": [119], "spatial": [121], "segmentations,": [125], "can": [126], "control": [127], "generated": [129], "image.": [130], "particular,": [132], "we": [133], "present": [134], "first": [136], "semantically-guided": [139], "megapixel": [142], "images": [143], "transformers.": [145], "Project": [146], "page": [147], "at": [148], "https://git.io/JLlvY.": [149]}