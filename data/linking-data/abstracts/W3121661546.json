{"Deep": [0], "learning-based": [1], "methods": [2, 147], "have": [3], "achieved": [4], "remarkable": [5], "success": [6], "in": [7, 39, 153], "image": [8, 35, 76, 122], "restoration": [9], "and": [10, 50, 113, 135, 158, 187], "enhancement,": [11], "but": [12], "are": [13, 190], "they": [14], "still": [15], "competitive": [16], "when": [17], "there": [18], "is": [19, 42, 172], "a": [20, 48, 51, 61, 115, 126, 130, 149], "lack": [21], "of": [22, 54, 90, 117, 151, 155], "paired": [23], "training": [24, 104], "data?": [25], "As": [26], "one": [27], "such": [28], "example,": [29], "this": [30], "paper": [31], "explores": [32], "the": [33, 55, 92, 102, 106, 110, 120, 136, 164], "low-light": [34, 49, 121], "enhancement": [36, 123], "problem,": [37, 124], "where": [38], "practice": [40], "it": [41], "extremely": [43], "challenging": [44], "to": [45, 80, 100, 163, 174, 178], "simultaneously": [46], "take": [47], "normal-light": [52], "photo": [53], "same": [56], "visual": [57, 156], "scene.": [58], "We": [59], "propose": [60, 99], "highly": [62], "effective": [63], "unsupervised": [64], "generative": [65], "adversarial": [66], "network,": [67], "dubbed": [68], "EnlightenGAN,": [69], "that": [70], "can": [71], "be": [72, 175], "trained": [73], "without": [74], "low/normal-light": [75], "pairs,": [77], "yet": [78], "proves": [79], "generalize": [81], "very": [82], "well": [83], "on": [84], "various": [85, 183], "real-world": [86, 180], "test": [87], "images.": [88], "Instead": [89], "supervising": [91], "learning": [93], "using": [94, 105], "ground": [95], "truth": [96], "data,": [97], "we": [98], "regularize": [101], "unpaired": [103, 169], "information": [107], "extracted": [108], "from": [109, 182], "input": [111], "itself,": [112], "benchmark": [114], "series": [116], "innovations": [118], "for": [119], "including": [125], "global-local": [127], "discriminator": [128], "structure,": [129], "self-regularized": [131], "perceptual": [132], "loss": [133], "fusion,": [134], "attention": [137], "mechanism.": [138], "Through": [139], "extensive": [140], "experiments,": [141], "our": [142], "proposed": [143], "approach": [144], "outperforms": [145], "recent": [146], "under": [148], "variety": [150], "metrics": [152], "terms": [154], "quality": [157], "subjective": [159], "user": [160], "study.": [161], "Thanks": [162], "great": [165], "flexibility": [166], "brought": [167], "by": [168], "training,": [170], "EnlightenGAN": [171], "demonstrated": [173], "easily": [176], "adaptable": [177], "enhancing": [179], "images": [181], "domains.": [184], "Our": [185], "codes": [186], "pre-trained": [188], "models": [189], "available": [191], "at:": [192], "https://github.com/VITA-Group/EnlightenGAN.": [193]}