{"Large,": [0], "pre-trained": [1], "language": [2, 41], "models": [3], "(PLMs)": [4], "such": [5], "as": [6, 57], "BERT": [7], "and": [8, 80, 100, 110], "GPT": [9], "have": [10, 26], "drastically": [11], "changed": [12], "the": [13, 58, 73, 85, 95], "Natural": [14], "Language": [15, 54], "Processing": [16], "(NLP)": [17], "field.": [18], "For": [19], "numerous": [20], "NLP": [21, 52, 89], "tasks,": [22], "approaches": [23], "leveraging": [24], "PLMs": [25], "achieved": [27], "state-of-the-art": [28], "performance.": [29], "The": [30], "key": [31, 74], "idea": [32], "is": [33], "to": [34, 87], "learn": [35], "a": [36, 43, 81], "generic,": [37], "latent": [38], "representation": [39], "of": [40, 77, 84], "from": [42], "generic": [44, 59], "task": [45], "once,": [46], "then": [47, 97], "share": [48], "it": [49, 106], "across": [50], "disparate": [51], "tasks.": [53], "modeling": [55], "serves": [56], "task,": [60], "one": [61], "with": [62], "abundant": [63], "self-supervised": [64], "text": [65, 101], "available": [66], "for": [67, 113], "extensive": [68], "training.": [69], "This": [70], "article": [71], "presents": [72], "fundamental": [75], "concepts": [76], "PLM": [78, 108], "architectures": [79], "comprehensive": [82], "view": [83], "shift": [86], "PLM-driven": [88], "techniques.": [90], "It": [91], "surveys": [92], "work": [93], "applying": [94], "pre-training": [96], "fine-tuning,": [98], "prompting,": [99], "generation": [102], "approaches.": [103], "In": [104], "addition,": [105], "discusses": [107], "limitations": [109], "suggested": [111], "directions": [112], "future": [114], "research.": [115]}