{"With": [0], "the": [1, 32, 41, 90, 101, 115], "rise": [2], "of": [3, 34, 60, 88], "powerful": [4], "pre-trained": [5, 46], "vision-language": [6, 47], "models": [7, 19], "like": [8], "CLIP,": [9], "it": [10], "becomes": [11], "essential": [12], "to": [13, 16, 20, 96, 133, 143, 151, 159, 172], "investigate": [14], "ways": [15], "adapt": [17, 150], "these": [18], "downstream": [21], "datasets.": [22], "A": [23], "recently": [24], "proposed": [25], "method": [26], "named": [27], "Context": [28, 120], "Optimization": [29, 121], "(CoOp)": [30], "introduces": [31], "concept": [33], "prompt": [35, 56], "learning\u2014a": [36], "recent": [37], "trend": [38], "in": [39, 54], "NLP\u2014to": [40], "vision": [42], "domain": [43, 186], "for": [44, 70, 135], "adapting": [45], "models.": [48], "Specifically,": [49], "CoOp": [50, 106, 125, 171], "turns": [51], "context": [52, 92], "words": [53], "a": [55, 58, 66, 85, 129, 180], "into": [57], "set": [59], "learnable": [61], "vectors": [62], "and,": [63], "with": [64], "only": [65], "few": [67], "labeled": [68], "images": [69], "learning,": [71], "can": [72], "achieve": [73], "huge": [74], "improvements": [75], "over": [76], "intensively-tuned": [77], "manual": [78], "prompts.": [79], "In": [80], "our": [81, 147], "study": [82], "we": [83, 117], "identify": [84], "critical": [86], "problem": [87], "CoOp:": [89], "learned": [91], "is": [93, 192], "not": [94], "generalizable": [95], "wider": [97], "unseen": [98, 173], "classes": [99, 109], "within": [100], "same": [102], "dataset,": [103], "suggesting": [104], "that": [105, 165], "overfits": [107], "base": [108], "observed": [110], "during": [111], "training.": [112], "To": [113], "address": [114], "problem,": [116], "propose": [118], "Conditional": [119], "(CoCoOp),": [122], "which": [123], "extends": [124], "by": [126], "further": [127], "learning": [128], "lightweight": [130], "neural": [131], "network": [132], "generate": [134], "each": [136, 152], "image": [137], "an": [138], "input-conditional": [139], "token": [140], "(vector).": [141], "Compared": [142], "CoOp's": [144], "static": [145], "prompts,": [146], "dynamic": [148], "prompts": [149], "instance": [153], "and": [154, 183], "are": [155], "thus": [156], "less": [157], "sensitive": [158], "class": [160], "shift.": [161], "Extensive": [162], "experiments": [163], "show": [164], "CoCoOp": [166], "generalizes": [167], "much": [168], "better": [169], "than": [170], "classes,": [174], "even": [175], "showing": [176], "promising": [177], "transferability": [178], "beyond": [179], "single": [181], "dataset;": [182], "yields": [184], "stronger": [185], "generalization": [187], "performance": [188], "as": [189], "well.": [190], "Code": [191], "available": [193], "at": [194], "https://github.com/KaiyangZhou/CoOp.": [195]}