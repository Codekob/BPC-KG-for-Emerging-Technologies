{"We": [0, 59], "introduce": [1], "a": [2, 28], "self-supervised": [3], "vision": [4, 35], "representation": [5, 13], "model": [6, 105, 129], "BEiT,": [7, 100], "which": [8], "stands": [9], "for": [10], "Bidirectional": [11], "Encoder": [12], "from": [14], "Image": [15], "Transformers.": [16, 36], "Following": [17], "BERT": [18], "developed": [19], "in": [20, 43], "the": [21, 62, 79, 88, 94, 104, 115, 154], "natural": [22], "language": [23], "processing": [24], "area,": [25], "we": [26, 69, 101], "propose": [27], "masked": [29], "image": [30, 39, 47, 64, 73, 96, 121], "modeling": [31], "task": [32, 112], "to": [33, 86], "pretrain": [34], "Specifically,": [37], "each": [38], "has": [40], "two": [41], "views": [42], "our": [44, 128], "pre-training,": [45], "i.e,": [46], "patches": [48, 74], "(such": [49], "as": [50], "16x16": [51], "pixels),": [52], "and": [53, 75, 123, 176], "visual": [54, 66, 90], "tokens": [55, 91], "(i.e.,": [56], "discrete": [57], "tokens).": [58], "first": [60], "\"tokenize\"": [61], "original": [63, 89], "into": [65, 78], "tokens.": [67], "Then": [68], "randomly": [70], "mask": [71], "some": [72], "fed": [76], "them": [77], "backbone": [80], "Transformer.": [81], "The": [82, 174], "pre-training": [83, 99, 135, 170], "objective": [84], "is": [85], "recover": [87], "based": [92], "on": [93, 107, 120, 145, 171], "corrupted": [95], "patches.": [97], "After": [98], "directly": [102], "fine-tune": [103], "parameters": [106], "downstream": [108], "tasks": [109], "by": [110], "appending": [111], "layers": [113], "upon": [114], "pretrained": [116, 177], "encoder.": [117], "Experimental": [118], "results": [119, 132], "classification": [122], "semantic": [124], "segmentation": [125], "show": [126], "that": [127], "achieves": [130, 141], "competitive": [131], "with": [133, 153, 168], "previous": [134], "methods.": [136], "For": [137], "example,": [138], "base-size": [139], "BEiT": [140, 159], "83.2%": [142], "top-1": [143], "accuracy": [144], "ImageNet-1K,": [146, 164], "significantly": [147], "outperforming": [148, 166], "from-scratch": [149], "DeiT": [150], "training": [151], "(81.8%)": [152], "same": [155], "setup.": [156], "Moreover,": [157], "large-size": [158], "obtains": [160], "86.3%": [161], "only": [162], "using": [163], "even": [165], "ViT-L": [167], "supervised": [169], "ImageNet-22K": [172], "(85.2%).": [173], "code": [175], "models": [178], "are": [179], "available": [180], "at": [181], "https://aka.ms/beit.": [182]}