{"Large": [0], "pre-trained": [1, 102, 120, 137], "language": [2, 108, 199, 213], "models": [3, 63, 99, 113, 171, 193, 206], "have": [4, 78], "been": [5, 81], "shown": [6], "to": [7, 27, 69], "store": [8], "factual": [9, 212], "knowledge": [10, 32, 57], "in": [11], "their": [12, 25, 41, 51, 55], "parameters,": [13], "and": [14, 29, 36, 53, 104, 123, 168, 180, 194, 211], "achieve": [15], "state-of-the-art": [16, 183, 216], "results": [17], "when": [18], "fine-tuned": [19], "on": [20, 38, 148, 172, 184], "downstream": [21, 86], "NLP": [22, 178], "tasks.": [23, 87], "However,": [24], "ability": [26], "access": [28, 67], "precisely": [30], "manipulate": [31], "is": [33, 118, 127], "still": [34], "limited,": [35], "hence": [37], "knowledge-intensive": [39, 177], "tasks,": [40, 189, 201], "performance": [42], "lags": [43], "behind": [44], "task-specific": [45, 195], "architectures.": [46, 197], "Additionally,": [47], "providing": [48], "provenance": [49], "for": [50, 84, 94, 107], "decisions": [52], "updating": [54], "world": [56], "remain": [58], "open": [59, 186], "research": [60], "problems.": [61], "Pre-trained": [62], "with": [64, 135], "a": [65, 90, 119, 128, 136, 173, 215], "differentiable": [66], "mechanism": [68], "explicit": [70], "non-parametric": [71, 105, 125], "memory": [72, 106, 117, 126], "can": [73, 160], "overcome": [74], "this": [75], "issue,": [76], "but": [77], "so": [79], "far": [80], "only": [82], "investigated": [83], "extractive": [85], "We": [88, 110, 140, 166], "explore": [89], "general-purpose": [91], "fine-tuning": [92], "recipe": [93], "retrieval-augmented": [95], "generation": [96, 200], "(RAG)": [97], "--": [98], "which": [100, 146], "combine": [101], "parametric": [103, 116, 191], "generation.": [109], "introduce": [111], "RAG": [112, 143, 205], "where": [114], "the": [115, 124, 149, 154, 158, 182], "seq2seq": [121, 192, 218], "model": [122], "dense": [129], "vector": [130], "index": [131], "of": [132, 176], "Wikipedia,": [133], "accessed": [134], "neural": [138], "retriever.": [139], "compare": [141], "two": [142], "formulations,": [144], "one": [145], "conditions": [147], "same": [150], "retrieved": [151], "passages": [152, 163], "across": [153], "whole": [155], "generated": [156], "sequence,": [157], "other": [159], "use": [161], "different": [162], "per": [164], "token.": [165], "fine-tune": [167], "evaluate": [169], "our": [170], "wide": [174], "range": [175], "tasks": [179], "set": [181], "three": [185], "domain": [187], "QA": [188], "outperforming": [190], "retrieve-and-extract": [196], "For": [198], "we": [202], "find": [203], "that": [204], "generate": [207], "more": [208], "specific,": [209], "diverse": [210], "than": [214], "parametric-only": [217], "baseline.": [219]}