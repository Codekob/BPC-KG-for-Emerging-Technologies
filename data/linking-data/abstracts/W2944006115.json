{"Research": [0], "on": [1, 115, 142], "depth-based": [2, 21, 193], "human": [3, 55, 67, 129, 196], "activity": [4, 112, 139, 197], "analysis": [5, 113], "achieved": [6], "outstanding": [7], "performance": [8, 105], "and": [9, 22, 52, 77, 85, 99, 118, 145, 186, 194], "demonstrated": [10], "the": [11, 33, 104, 120, 167, 173, 181], "effectiveness": [12], "of": [13, 30, 35, 41, 54, 106, 109, 122, 166, 175], "3D": [14, 111, 138], "representation": [15], "for": [16, 65, 127, 157, 164, 192], "action": [17, 24, 68, 94, 130, 169], "recognition.": [18, 131], "The": [19], "existing": [20, 110], "RGB+D-based": [23, 195], "recognition": [25, 140, 165], "benchmarks": [26], "have": [27], "a": [28, 62, 107, 135, 146], "number": [29, 40], "limitations,": [31], "including": [32, 96], "lack": [34], "large-scale": [36, 63, 177], "training": [37], "samples,": [38], "realistic": [39], "distinct": [42, 75], "class": [43], "categories,": [44], "diversity": [45], "in": [46], "camera": [47], "views,": [48], "varied": [49], "environmental": [50], "conditions,": [51], "variety": [53], "subjects.": [56], "In": [57], "this": [58, 116, 158, 176], "work,": [59], "we": [60, 133], "introduce": [61], "dataset": [64, 90, 178, 200], "RGB+D": [66], "recognition,": [69], "which": [70, 160], "is": [71, 155, 201], "collected": [72], "from": [73], "106": [74], "subjects": [76], "contains": [78, 91], "more": [79], "than": [80], "114": [81], "thousand": [82], "video": [83], "samples": [84], "8": [86], "million": [87], "frames.": [88], "This": [89], "120": [92], "different": [93], "classes": [95], "daily,": [97], "mutual,": [98], "health-related": [100], "activities.": [101], "We": [102, 171], "evaluate": [103], "series": [108], "methods": [114, 126], "dataset,": [117, 144], "show": [119], "advantage": [121], "applying": [123], "deep": [124], "learning": [125, 190], "3D-based": [128], "Furthermore,": [132], "investigate": [134], "novel": [136, 168], "one-shot": [137], "problem": [141], "our": [143], "simple": [147], "yet": [148], "effective": [149], "Action-Part": [150], "Semantic": [151], "Relevance-aware": [152], "(APSR)": [153], "framework": [154], "proposed": [156], "task,": [159], "yields": [161], "promising": [162], "results": [163], "classes.": [170], "believe": [172], "introduction": [174], "will": [179], "enable": [180], "community": [182], "to": [183], "apply,": [184], "adapt,": [185], "develop": [187], "various": [188], "data-hungry": [189], "techniques": [191], "understanding.": [198], "[The": [199], "available": [202], "at:": [203], "http://rose1.ntu.edu.sg/Datasets/actionRecognition.asp]": [204]}