{"We": [0, 78, 102], "present": [1], "ControlNet,": [2], "a": [3, 39, 44], "neural": [4, 51], "network": [5], "architecture": [6, 52], "to": [7, 12, 42, 127], "add": [8], "spatial": [9], "conditioning": [10, 81], "controls": [11], "large,": [13], "pretrained": [14, 33], "text-to-image": [15], "diffusion": [16, 23, 130], "models.": [17, 131], "ControlNet": [18, 122], "locks": [19], "the": [20, 64, 76, 105], "production-ready": [21], "large": [22, 115], "models,": [24], "and": [25, 29, 68, 114], "reuses": [26], "their": [27], "deep": [28], "robust": [30, 110], "encoding": [31], "layers": [32], "with": [34, 55, 90, 98, 111], "billions": [35], "of": [36, 47, 107], "images": [37], "as": [38], "strong": [40], "backbone": [41], "learn": [43], "diverse": [45], "set": [46], "conditional": [48], "controls.": [49], "The": [50], "is": [53, 109], "connected": [54], "\"zero": [56], "convolutions\"": [57], "(zero-initialized": [58], "convolution": [59], "layers)": [60], "that": [61, 70, 104, 121], "progressively": [62], "grow": [63], "parameters": [65], "from": [66], "zero": [67], "ensure": [69], "no": [71], "harmful": [72], "noise": [73], "could": [74], "affect": [75], "finetuning.": [77], "test": [79], "various": [80], "controls,": [82], "e.g.,": [83], "edges,": [84], "depth,": [85], "segmentation,": [86], "human": [87], "pose,": [88], "etc.,": [89], "Stable": [91], "Diffusion,": [92], "using": [93], "single": [94], "or": [95, 99], "multiple": [96], "conditions,": [97], "without": [100], "prompts.": [101], "show": [103, 120], "training": [106], "ControlNets": [108], "small": [112], "(<50k)": [113], "(>1m)": [116], "datasets.": [117], "Extensive": [118], "results": [119], "may": [123], "facilitate": [124], "wider": [125], "applications": [126], "control": [128], "image": [129]}