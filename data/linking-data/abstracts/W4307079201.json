{"Finetuning": [0], "language": [1, 155], "models": [2], "on": [3, 34, 49, 64, 92, 103, 110, 116], "a": [4, 31, 65, 99, 144], "collection": [5], "of": [6, 39, 67, 153], "datasets": [7], "phrased": [8], "as": [9, 114, 137], "instructions": [10], "has": [11], "been": [12], "shown": [13], "to": [14, 20, 132], "improve": [15], "model": [16, 44, 68], "performance": [17, 63, 109, 129, 150], "and": [18, 46, 78, 151], "generalization": [19], "unseen": [21], "tasks.": [22], "In": [23], "this": [24], "paper": [25], "we": [26], "explore": [27], "instruction": [28, 55, 141], "finetuning": [29, 48, 56, 142], "with": [30, 57], "particular": [32], "focus": [33], "(1)": [35], "scaling": [36, 42], "the": [37, 43, 58, 149], "number": [38], "tasks,": [40], "(2)": [41], "size,": [45], "(3)": [47], "chain-of-thought": [50], "data.": [51], "We": [52, 119], "find": [53], "that": [54], "above": [59], "aspects": [60], "dramatically": [61], "improves": [62], "variety": [66], "classes": [69], "(PaLM,": [70], "T5,": [71], "U-PaLM),": [72], "prompting": [73], "setups": [74], "(zero-shot,": [75], "few-shot,": [76], "CoT),": [77], "evaluation": [79], "benchmarks": [80], "(MMLU,": [81], "BBH,": [82], "TyDiQA,": [83], "MGSM,": [84], "open-ended": [85], "generation).": [86], "For": [87], "instance,": [88], "Flan-PaLM": [89, 105], "540B": [90, 97, 106], "instruction-finetuned": [91], "1.8K": [93], "tasks": [94], "outperforms": [95], "PALM": [96], "by": [98], "large": [100], "margin": [101], "(+9.4%": [102], "average).": [104], "achieves": [107], "state-of-the-art": [108], "several": [111], "benchmarks,": [112], "such": [113, 136], "75.2%": [115], "five-shot": [117], "MMLU.": [118], "also": [120], "publicly": [121], "release": [122], "Flan-T5": [123], "checkpoints,": [124], "which": [125], "achieve": [126], "strong": [127], "few-shot": [128], "even": [130], "compared": [131], "much": [133], "larger": [134], "models,": [135], "PaLM": [138], "62B.": [139], "Overall,": [140], "is": [143], "general": [145], "method": [146], "for": [147], "improving": [148], "usability": [152], "pretrained": [154], "models.": [156]}