{"Transformer": [0, 104, 106], "is": [1, 60, 190, 208, 216], "a": [2, 100], "new": [3, 101], "kind": [4], "of": [5, 45, 56, 67, 135, 154, 174, 196], "neural": [6], "architecture": [7], "which": [8, 189], "encodes": [9], "the": [10, 17, 21, 26, 54, 57, 81, 111, 145, 164, 172, 175, 187, 197, 213], "input": [11, 27], "data": [12], "as": [13, 116, 130], "powerful": [14], "features": [15, 66], "via": [16], "attention": [18, 82, 134], "mechanism.": [19], "Basically,": [20], "visual": [22, 92, 147, 199], "transformers": [23, 93], "first": [24], "divide": [25, 123], "images": [28, 43], "into": [29, 125], "several": [30, 169], "local": [31, 85, 112], "patches": [32, 86, 113, 127], "and": [33, 38, 51, 72, 97, 119, 157, 212], "then": [34], "calculate": [35], "both": [36, 155], "representations": [37], "their": [39], "relationship.": [40], "Since": [41], "natural": [42], "are": [44, 87], "high": [46, 95], "complexity": [47], "with": [48, 94, 141, 149, 201], "abundant": [49], "detail": [50], "color": [52], "information,": [53], "granularity": [55], "patch": [58], "dividing": [59], "not": [61], "fine": [62], "enough": [63], "for": [64, 90], "excavating": [65], "objects": [68], "in": [69, 144], "different": [70], "scales": [71], "locations.": [73], "In": [74], "this": [75], "paper,": [76], "we": [77, 98, 109, 180], "point": [78], "out": [79], "that": [80, 195], "inside": [83], "these": [84], "also": [88], "essential": [89], "building": [91], "performance": [96], "explore": [99], "architecture,": [102, 178], "namely,": [103], "iN": [105], "(TNT).": [107], "Specifically,": [108], "regard": [110], "(e.g.,": [114, 128], "16$\\times$16)": [115], "\"visual": [117, 131], "sentences\"": [118], "present": [120], "to": [121, 162], "further": [122], "them": [124], "smaller": [126], "4$\\times$4)": [129], "words\".": [132], "The": [133, 205], "each": [136], "word": [137], "will": [138, 159], "be": [139, 160], "calculated": [140], "other": [142], "words": [143, 156], "given": [146], "sentence": [148], "negligible": [150], "computational": [151, 203], "costs.": [152], "Features": [153], "sentences": [158], "aggregated": [161], "enhance": [163], "representation": [165], "ability.": [166], "Experiments": [167], "on": [168, 186], "benchmarks": [170], "demonstrate": [171], "effectiveness": [173], "proposed": [176], "TNT": [177], "e.g.,": [179], "achieve": [181], "an": [182], "81.5%": [183], "top-1": [184], "accuracy": [185], "ImageNet,": [188], "about": [191], "1.7%": [192], "higher": [193], "than": [194], "state-of-the-art": [198], "transformer": [200], "similar": [202], "cost.": [204], "PyTorch": [206], "code": [207, 215], "available": [209, 217], "at": [210, 218], "https://github.com/huawei-noah/CV-Backbones,": [211], "MindSpore": [214], "https://gitee.com/mindspore/models/tree/master/research/cv/TNT.": [219]}