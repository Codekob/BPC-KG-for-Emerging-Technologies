{"Recent": [0], "studies": [1], "on": [2], "mobile": [3, 48, 173], "network": [4], "design": [5], "have": [6], "demonstrated": [7], "the": [8, 15, 26, 79, 95, 121, 148, 154, 157], "remarkable": [9], "effectiveness": [10], "of": [11, 136, 156, 159], "channel": [12, 55, 63, 83], "attention": [13, 36, 45, 64, 81, 84, 140, 163, 192], "(e.g.,": [14], "Squeeze-and-Excitation": [16], "attention)": [17], "for": [18, 32, 47], "lifting": [19], "model": [20], "performance,": [21], "but": [22, 200], "they": [23], "generally": [24], "neglect": [25], "positional": [27, 52, 115], "information,": [28], "which": [29, 57], "is": [30, 164, 193, 216], "important": [31], "generating": [33], "spatially": [34], "selective": [35], "maps.": [37], "In": [38, 100], "this": [39, 101], "paper,": [40], "we": [41, 58], "propose": [42], "a": [43, 67, 71, 134], "novel": [44], "mechanism": [46], "networks": [49], "by": [50], "embedding": [51], "information": [53, 116], "into": [54, 85, 133, 171], "attention,": [56], "call": [59], "\"coordinate": [60], "attention\".": [61], "Unlike": [62], "that": [65, 91, 142, 189], "transforms": [66], "feature": [68, 73, 88, 127, 150], "tensor": [69], "to": [70, 147, 152, 197], "single": [72], "vector": [74], "via": [75], "2D": [76], "global": [77], "pooling,": [78], "coordinate": [80, 162, 191], "factorizes": [82], "two": [86, 96], "1D": [87], "encoding": [89], "processes": [90], "aggregate": [92], "features": [93], "along": [94, 108, 120], "spatial": [97, 110, 123], "directions,": [98], "respectively.": [99], "way,": [102], "long-range": [103], "dependencies": [104], "can": [105, 117, 143, 167], "be": [106, 118, 144, 168], "captured": [107], "one": [109], "direction": [111], "and": [112, 138, 166, 179, 212], "meanwhile": [113], "precise": [114], "preserved": [119], "other": [122], "direction.": [124], "The": [125], "resulting": [126], "maps": [128, 141], "are": [129], "then": [130], "encoded": [131], "separately": [132], "pair": [135], "direction-aware": [137], "position-sensitive": [139], "complementarily": [145], "applied": [146], "input": [149], "map": [151], "augment": [153], "representations": [155], "objects": [158], "interest.": [160], "Our": [161], "simple": [165], "flexibly": [169], "plugged": [170], "classic": [172], "networks,": [174], "such": [175, 208], "as": [176, 209], "MobileNetV2,": [177], "MobileNeXt,": [178], "EfficientNet": [180], "with": [181], "nearly": [182], "no": [183], "computational": [184], "overhead.": [185], "Extensive": [186], "experiments": [187], "demonstrate": [188], "our": [190], "not": [194], "only": [195], "beneficial": [196], "ImageNet": [198], "classification": [199], "more": [201], "interestingly,": [202], "behaves": [203], "better": [204], "in": [205], "down-stream": [206], "tasks,": [207], "object": [210], "detection": [211], "semantic": [213], "segmentation.": [214], "Code": [215], "available": [217], "at": [218], "https://github.com/Andrew-Qibin/CoordAttention.": [219]}