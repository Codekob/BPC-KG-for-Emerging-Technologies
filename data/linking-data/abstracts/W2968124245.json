{"We": [0, 41], "propose": [1, 43], "VisualBERT,": [2], "a": [3, 10, 19], "simple": [4], "and": [5, 32, 65, 97, 110], "flexible": [6], "framework": [7], "for": [8, 49, 105], "modeling": [9], "broad": [11], "range": [12], "of": [13, 18, 21, 28, 88], "vision-and-language": [14, 59], "tasks.": [15], "VisualBERT": [16, 51, 69, 84], "consists": [17], "stack": [20], "Transformer": [22], "layers": [23], "that": [24, 68, 83], "implicitly": [25], "align": [26], "elements": [27, 87], "an": [29, 35], "input": [30, 37], "text": [31], "regions": [33, 92, 112], "in": [34], "associated": [36], "image": [38, 53, 91, 111], "with": [39, 73], "self-attention.": [40], "further": [42], "two": [44], "visually-grounded": [45], "language": [46, 89], "model": [47], "objectives": [48], "pre-training": [50], "on": [52, 57], "caption": [54], "data.": [55], "Experiments": [56], "four": [58], "tasks": [60], "including": [61], "VQA,": [62], "VCR,": [63], "NLVR2,": [64], "Flickr30K": [66], "show": [67], "outperforms": [70], "or": [71], "rivals": [72], "state-of-the-art": [74], "models": [75], "while": [76], "being": [77], "significantly": [78], "simpler.": [79], "Further": [80], "analysis": [81], "demonstrates": [82], "can": [85], "ground": [86], "to": [90, 101, 114], "without": [93], "any": [94], "explicit": [95], "supervision": [96], "is": [98], "even": [99], "sensitive": [100], "syntactic": [102], "relationships,": [103], "tracking,": [104], "example,": [106], "associations": [107], "between": [108], "verbs": [109], "corresponding": [113], "their": [115], "arguments.": [116]}