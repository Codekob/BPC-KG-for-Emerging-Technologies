{"Driven": [0], "by": [1, 30], "improved": [2], "architectures": [3], "and": [4, 18, 91, 118, 147], "better": [5], "representation": [6], "learning": [7, 48, 59, 116], "frameworks,": [8], "the": [9, 22, 104, 133], "field": [10], "of": [11, 114, 135, 157], "visual": [12], "recognition": [13, 140], "has": [14], "enjoyed": [15], "rapid": [16], "modernization": [17], "performance": [19, 36, 134], "boost": [20], "in": [21, 37, 122], "early": [23], "2020s.": [24], "For": [25], "example,": [26], "modern": [27], "ConvNets,": [28], "represented": [29], "ConvNeXt": [31, 105, 128, 154], "[33],": [32], "have": [33], "demonstrated": [34], "strong": [35], "various": [38, 139, 158], "scenarios.": [39], "While": [40], "these": [41, 73], "models": [42, 156], "were": [43], "originally": [44], "designed": [45], "for": [46], "supervised": [47], "with": [49, 167], "ImageNet": [50, 143], "labels,": [51], "they": [52], "can": [53, 100], "also": [54, 151], "potentially": [55], "benefit": [56], "from": [57, 161], "self-supervised": [58, 115], "techniques": [60, 117], "such": [61], "as": [62], "masked": [63, 88], "autoencoders": [64], "(MAE)": [65], "[14].": [66], "However,": [67], "we": [68, 83], "found": [69], "that": [70, 99, 178], "simply": [71], "combining": [72], "two": [74], "approaches": [75], "leads": [76], "to": [77, 103, 107, 173], "subpar": [78], "performance.": [79], "In": [80], "this": [81], "paper,": [82], "propose": [84], "a": [85, 92, 123, 174, 180], "fully": [86], "convolutional": [87], "autoencoder": [89], "framework": [90], "new": [93, 124], "Global": [94], "Response": [95], "Normalization": [96], "(GRN)": [97], "layer": [98], "be": [101], "added": [102], "architecture": [106], "enhance": [108], "inter-channel": [109], "feature": [110], "competition.": [111], "This": [112], "co-design": [113], "architectural": [119], "improvement": [120], "results": [121], "model": [125, 166, 177], "family": [126], "called": [127], "V2,": [129], "which": [130], "significantly": [131], "improves": [132], "pure": [136], "ConvNets": [137], "on": [138, 171], "benchmarks,": [141], "including": [142], "classification,": [144], "COCO": [145], "detection,": [146], "ADE20K": [148], "segmentation.": [149], "We": [150], "provide": [152], "pre-trained": [153], "V2": [155], "sizes,": [159], "ranging": [160], "an": [162], "efficient": [163], "3.7M-parameter": [164], "Atto": [165], "76.7%": [168], "top-1": [169], "accuracy": [170, 183], "ImageNet,": [172], "650M": [175], "Huge": [176], "achieves": [179], "state-of-the-art": [181], "88.9%": [182], "using": [184], "only": [185], "public": [186], "training": [187], "data.": [188]}