{"We": [0, 17, 61, 126], "show": [1], "that": [2, 104], "diffusion": [3, 111], "models": [4], "can": [5], "achieve": [6, 18, 62], "image": [7, 22, 36], "sample": [8, 41], "quality": [9, 42], "superior": [10], "to": [11, 116], "the": [12, 99], "current": [13], "state-of-the-art": [14], "generative": [15], "models.": [16], "this": [19], "on": [20, 67, 71, 76, 118, 123], "unconditional": [21], "synthesis": [23], "by": [24], "finding": [25], "a": [26, 30, 46, 59], "better": [27, 96], "architecture": [28], "through": [29], "series": [31], "of": [32, 65, 98], "ablations.": [33], "For": [34], "conditional": [35], "synthesis,": [37], "we": [38, 80, 102], "further": [39, 113], "improve": [40], "with": [43, 84, 109], "classifier": [44, 105], "guidance:": [45], "simple,": [47], "compute-efficient": [48], "method": [49], "for": [50, 54], "trading": [51], "off": [52], "diversity": [53], "fidelity": [55], "using": [56], "gradients": [57], "from": [58], "classifier.": [60], "an": [63], "FID": [64, 115], "2.97": [66], "ImageNet": [68, 72, 77, 119, 124], "128$\\times$128,": [69], "4.59": [70], "256$\\times$256,": [73], "and": [74, 79, 121], "7.72": [75], "512$\\times$512,": [78], "match": [81], "BigGAN-deep": [82], "even": [83], "as": [85, 87], "few": [86], "25": [88], "forward": [89], "passes": [90], "per": [91], "sample,": [92], "all": [93], "while": [94], "maintaining": [95], "coverage": [97], "distribution.": [100], "Finally,": [101], "find": [103], "guidance": [106], "combines": [107], "well": [108], "upsampling": [110], "models,": [112], "improving": [114], "3.94": [117], "256$\\times$256": [120], "3.85": [122], "512$\\times$512.": [125], "release": [127], "our": [128], "code": [129], "at": [130], "https://github.com/openai/guided-diffusion": [131]}