{"Convolutional": [0], "Neural": [1], "Networks": [2], "(CNNs)": [3], "are": [4, 33, 42], "the": [5, 16, 71, 121], "go-to": [6], "model": [7], "for": [8, 36], "computer": [9], "vision.": [10], "Recently,": [11], "attention-based": [12], "networks,": [13], "such": [14], "as": [15], "Vision": [17], "Transformer,": [18], "have": [19], "also": [20], "become": [21], "popular.": [22], "In": [23], "this": [24], "paper": [25], "we": [26], "show": [27], "that": [28, 114], "while": [29], "convolutions": [30], "and": [31, 74, 105, 127], "attention": [32], "both": [34], "sufficient": [35], "good": [37], "performance,": [38], "neither": [39], "of": [40, 59, 123], "them": [41], "necessary.": [43], "We": [44, 112], "present": [45], "MLP-Mixer,": [46], "an": [47], "architecture": [48], "based": [49], "exclusively": [50], "on": [51, 87, 99], "multi-layer": [52], "perceptrons": [53], "(MLPs).": [54], "MLP-Mixer": [55, 95], "contains": [56], "two": [57], "types": [58], "layers:": [60], "one": [61, 75], "with": [62, 76, 91, 103], "MLPs": [63, 77], "applied": [64, 78], "independently": [65], "to": [66, 109], "image": [67, 100], "patches": [68, 80], "(i.e.": [69, 81], "\"mixing\"": [70, 82], "per-location": [72], "features),": [73], "across": [79], "spatial": [83], "information).": [84], "When": [85], "trained": [86], "large": [88], "datasets,": [89], "or": [90], "modern": [92], "regularization": [93], "schemes,": [94], "attains": [96], "competitive": [97], "scores": [98], "classification": [101], "benchmarks,": [102], "pre-training": [104], "inference": [106], "cost": [107], "comparable": [108], "state-of-the-art": [110], "models.": [111], "hope": [113], "these": [115], "results": [116], "spark": [117], "further": [118], "research": [119], "beyond": [120], "realms": [122], "well": [124], "established": [125], "CNNs": [126], "Transformers.": [128]}