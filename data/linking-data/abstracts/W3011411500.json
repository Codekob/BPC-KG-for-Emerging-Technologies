{"We": [0, 106], "present": [1], "SpanBERT,": [2], "a": [3, 109], "pre-training": [4], "method": [5], "that": [6], "is": [7], "designed": [8], "to": [9, 38], "better": [10], "represent": [11], "and": [12, 31, 60, 75, 85, 97, 103, 131], "predict": [13, 39], "spans": [14], "of": [15, 43, 112], "text.": [16], "Our": [17], "approach": [18], "extends": [19], "BERT": [20, 59, 89], "by": [21], "(1)": [22], "masking": [23], "contiguous": [24], "random": [25, 29], "spans,": [26], "rather": [27], "than": [28], "tokens,": [30], "(2)": [32], "training": [33, 83], "the": [34, 40, 44, 50, 81, 113, 116, 126], "span": [35, 68], "boundary": [36], "representations": [37, 53], "entire": [41], "content": [42], "masked": [45], "span,": [46], "without": [47], "relying": [48], "on": [49, 67, 100, 115, 125, 134], "individual": [51], "token": [52], "within": [54], "it.": [55], "SpanBERT": [56], "consistently": [57], "outperforms": [58], "our": [61, 92], "better-tuned": [62], "baselines,": [63], "with": [64, 80], "substantial": [65], "gains": [66, 133], "selection": [69], "tasks": [70], "such": [71], "as": [72, 88], "question": [73], "answering": [74], "coreference": [76, 118], "resolution.": [77], "In": [78], "particular,": [79], "same": [82], "data": [84], "model": [86, 94], "size": [87], "large": [90], ",": [91], "single": [93], "obtains": [95], "94.6%": [96], "88.7%": [98], "F1": [99], "SQuAD": [101], "1.1": [102], "2.0": [104], "respectively.": [105], "also": [107], "achieve": [108], "new": [110], "state": [111], "art": [114], "OntoNotes": [117], "resolution": [119], "task": [120], "(79.6%": [121], "F1),": [122], "strong": [123], "performance": [124], "TACRED": [127], "relation": [128], "extraction": [129], "benchmark,": [130], "even": [132], "GLUE.": [135], "1": [136]}