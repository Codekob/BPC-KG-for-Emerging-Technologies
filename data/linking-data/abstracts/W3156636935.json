{"This": [0, 41], "paper": [1], "presents": [2], "SimCSE,": [3], "a": [4, 31, 68, 74, 132], "simple": [5, 42], "contrastive": [6, 32, 88, 148], "learning": [7, 89, 149], "framework": [8], "that": [9, 56], "greatly": [10], "advances": [11], "the": [12], "state-of-the-art": [13], "sentence": [14, 26], "embeddings.": [15], "We": [16, 54, 103, 142], "first": [17], "describe": [18], "an": [19, 24, 123], "unsupervised": [20, 115], "approach,": [21, 76], "which": [22, 77], "takes": [23], "input": [25], "and": [27, 63, 97, 113, 116, 127, 134, 146, 160], "predicts": [28], "itself": [29], "in": [30], "objective,": [33], "with": [34, 50], "only": [35], "standard": [36, 107], "dropout": [37, 57], "used": [38], "as": [39, 59, 95, 100], "noise.": [40], "method": [43], "works": [44], "surprisingly": [45], "well,": [46], "performing": [47], "on": [48, 106], "par": [49], "previous": [51, 139], "supervised": [52, 75, 117, 167], "counterparts.": [53], "find": [55], "acts": [58], "minimal": [60], "data": [61], "augmentation": [62], "removing": [64], "it": [65, 161], "leads": [66], "to": [67, 138, 156], "representation": [69], "collapse.": [70], "Then,": [71], "we": [72], "propose": [73], "incorporates": [78], "annotated": [79], "pairs": [80, 94, 99, 165], "from": [81], "natural": [82], "language": [83], "inference": [84], "datasets": [85], "into": [86], "our": [87, 114], "framework,": [90], "by": [91], "using": [92, 119], "\u201centailment\u201d": [93], "positives": [96], "\u201ccontradiction\u201d": [98], "hard": [101], "negatives.": [102], "evaluate": [104], "SimCSE": [105], "semantic": [108], "textual": [109], "similarity": [110], "(STS)": [111], "tasks,": [112], "models": [118], "BERT": [120], "base": [121], "achieve": [122], "average": [124], "of": [125], "76.3%": [126], "81.6%": [128], "Spearman\u2019s": [129], "correlation": [130], "respectively,": [131], "4.2%": [133], "2.2%": [135], "improvement": [136], "compared": [137], "best": [140], "results.": [141], "also": [143], "show\u2014both": [144], "theoretically": [145], "empirically\u2014that": [147], "objective": [150], "regularizes": [151], "pre-trained": [152], "embeddings\u2019": [153], "anisotropic": [154], "space": [155], "be": [157], "more": [158], "uniform,": [159], "better": [162], "aligns": [163], "positive": [164], "when": [166], "signals": [168], "are": [169], "available.": [170]}