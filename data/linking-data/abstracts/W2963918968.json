{"Designing": [0], "convolutional": [1], "neural": [2, 63], "networks": [3], "(CNN)": [4], "for": [5, 211], "mobile": [6, 11, 32, 62, 120, 158], "devices": [7], "is": [8, 38, 99, 184, 216], "challenging": [9], "because": [10], "models": [12, 160], "need": [13], "to": [14, 28, 41, 53], "be": [15], "small": [16], "and": [17, 30, 92, 130, 193], "fast,": [18], "yet": [19], "still": [20], "accurate.": [21], "Although": [22], "significant": [23], "efforts": [24], "have": [25], "been": [26], "dedicated": [27], "design": [29], "improve": [31], "CNNs": [33], "on": [34, 119, 179], "all": [35], "dimensions,": [36], "it": [37], "very": [39], "difficult": [40], "manually": [42], "balance": [43, 127], "these": [44], "trade-offs": [45], "when": [46], "there": [47], "are": [48], "so": [49, 77], "many": [50], "architectural": [51], "possibilities": [52], "consider.": [54], "In": [55], "this": [56], "paper,": [57], "we": [58, 134], "propose": [59, 135], "an": [60], "automated": [61], "architecture": [64], "search": [65, 80, 131, 140], "(MNAS)": [66], "approach,": [67], "which": [68, 183], "explicitly": [69], "incorporate": [70], "model": [71, 84, 118], "latency": [72, 98, 114, 178], "into": [73], "the": [74, 79, 117, 125, 147, 166], "main": [75], "objective": [76], "that": [78, 85, 142, 152], "can": [81], "identify": [82], "a": [83, 87, 136, 180], "achieves": [86, 172, 205], "good": [88], "trade-off": [89], "between": [90, 128], "accuracy": [91, 175, 192], "latency.": [93], "Unlike": [94], "previous": [95], "work,": [96], "where": [97], "considered": [100], "via": [101], "another,": [102], "often": [103], "inaccurate": [104], "proxy": [105], "(e.g.,": [106], "FLOPS),": [107], "our": [108, 153, 170], "approach": [109, 154], "directly": [110], "measures": [111], "real-world": [112], "inference": [113], "by": [115], "executing": [116], "phones.": [121], "To": [122], "further": [123], "strike": [124], "right": [126], "flexibility": [129], "space": [132, 141], "size,": [133], "novel": [137], "factorized": [138], "hierarchical": [139], "encourages": [143], "layer": [144], "diversity": [145], "throughout": [146], "network.": [148], "Experimental": [149], "results": [150], "show": [151], "consistently": [155], "outperforms": [156], "state-of-the-art": [157], "CNN": [159], "across": [161], "multiple": [162], "vision": [163], "tasks.": [164], "On": [165], "ImageNet": [167], "classification": [168], "task,": [169], "MnasNet": [171, 203], "75.2%": [173], "top-1": [174], "with": [176, 189, 198], "78ms": [177], "Pixel": [181], "phone,": [182], "1.8\u00d7": [185], "faster": [186, 195], "than": [187, 196, 209], "MobileNetV2": [188], "0.5%": [190], "higher": [191, 200], "2.3\u00d7": [194], "NASNet": [197], "1.2%": [199], "accuracy.": [201], "Our": [202], "also": [204], "better": [206], "mAP": [207], "quality": [208], "MobileNets": [210], "COCO": [212], "object": [213], "detection.": [214], "Code": [215], "at": [217], "https://github.com/tensorflow/tpu/tree/master/models/official/mnasnet.": [218]}