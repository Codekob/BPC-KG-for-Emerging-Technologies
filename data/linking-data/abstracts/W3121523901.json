{"Transformers,": [0], "which": [1, 133], "are": [2], "popular": [3], "for": [4, 10, 20, 48, 113, 182], "language": [5], "modeling,": [6], "have": [7], "been": [8], "explored": [9], "solving": [11], "vision": [12, 183], "tasks": [13], "recently,": [14], "e.g.,": [15], "the": [16, 73, 82, 101, 144, 196], "Vision": [17, 130], "Transformer": [18, 41, 131], "(ViT)": [19], "image": [21, 28, 145, 249], "classification.": [22, 49], "The": [23], "ViT": [24, 51, 107, 203], "model": [25, 44, 81], "splits": [26], "each": [27], "into": [29, 153], "a": [30, 62, 127, 136, 179], "sequence": [31], "of": [32, 76, 106, 201], "tokens": [33, 147, 164, 169], "with": [34, 178, 226, 236], "fixed": [35, 114], "length": [36, 170], "and": [37, 89, 117, 168, 199, 222], "then": [38], "applies": [39], "multiple": [40], "layers": [42], "to": [43, 55, 80, 95, 109, 141, 146, 239], "their": [45], "global": [46], "relation": [47], "However,": [50], "achieves": [52, 223], "inferior": [53], "performance": [54, 225], "CNNs": [56], "when": [57, 212], "trained": [58, 213], "from": [59, 214], "scratch": [60, 215], "on": [61, 216, 231, 252], "midsize": [63], "dataset": [64], "like": [65], "ImageNet.": [66, 217, 232, 253], "We": [67], "find": [68], "it": [69], "is": [70], "because:": [71], "1)": [72, 135], "simple": [74], "tokenization": [75], "input": [77], "images": [78], "fails": [79], "important": [83], "local": [84, 159], "structure": [85, 160, 181], "such": [86, 123, 157], "as": [87], "edges": [88], "lines": [90], "among": [91], "neighboring": [92, 151], "pixels,": [93], "leading": [94], "low": [96], "training": [97, 119, 230], "sample": [98], "efficiency;": [99], "2)": [100, 174], "redundant": [102], "attention": [103], "backbone": [104, 177], "design": [105, 189], "leads": [108], "limited": [110, 118], "feature": [111], "richness": [112], "computation": [115], "budgets": [116], "samples.": [120], "To": [121], "overcome": [122], "limitations,": [124], "we": [125], "propose": [126], "new": [128], "Tokens-To-Token": [129], "(T2T-VTT),": [132], "incorporates": [134], "layer-wise": [137], "Tokens-to-Token": [138], "(T2T)": [139], "transformation": [140], "progressively": [142], "structurize": [143], "by": [148, 162, 186, 204, 228], "recursively": [149], "aggregating": [150], "Tokens": [152], "one": [154], "Token": [155], "(Tokens-to-Token),": [156], "that": [158], "represented": [161], "surrounding": [163], "can": [165, 171, 243], "be": [166, 172], "modeled": [167], "reduced;": [173], "an": [175], "efficient": [176], "deep-narrow": [180], "transformer": [184], "motivated": [185], "CNN": [187], "architecture": [188], "after": [190], "empirical": [191], "study.": [192], "Notably,": [193], "T2T-ViT": [194, 235], "reduces": [195], "parameter": [197], "count": [198], "MACs": [200], "vanilla": [202], "half,": [205], "while": [206], "achieving": [207], "more": [208], "than": [209], "3.0%": [210], "improvement": [211], "It": [218], "also": [219], "outperforms": [220], "ResNets": [221], "comparable": [224, 237], "MobileNets": [227], "directly": [229], "For": [233], "example,": [234], "size": [238], "ResNet50": [240], "(21.5M": [241], "parameters)": [242], "achieve": [244], "83.3%": [245], "top1": [246], "accuracy": [247], "in": [248], "resolution": [250], "384x384": [251], "<sup": [254], "xmlns:mml=\"http://www.w3.org/1998/Math/MathML\"": [255], "xmlns:xlink=\"http://www.w3.org/1999/xlink\">1</sup>": [256]}