{"The": [0], "recent": [1], "GPT-4": [2, 36, 50], "has": [3], "demonstrated": [4, 109], "extraordinary": [5], "multi-modal": [6, 46, 107], "abilities,": [7], "such": [8, 112], "as": [9, 113], "directly": [10], "generating": [11], "websites": [12], "from": [13, 52, 121], "handwritten": [14], "text": [15], "and": [16, 118, 136, 151, 175, 203, 210], "identifying": [17], "humorous": [18], "elements": [19], "within": [20], "images.": [21], "These": [22], "features": [23, 96], "are": [24, 213], "rarely": [25], "observed": [26], "in": [27, 131, 188], "previous": [28], "vision-language": [29], "models.": [30], "However,": [31], "the": [32, 44, 53, 87, 94, 160, 189, 194, 199], "technical": [33], "details": [34], "behind": [35], "continue": [37], "to": [38, 145, 192], "remain": [39], "undisclosed.": [40], "We": [41], "believe": [42], "that": [43, 91, 159], "enhanced": [45], "generation": [47, 117, 201], "capabilities": [48, 130], "of": [49, 55], "stem": [51], "utilization": [54], "sophisticated": [56], "large": [57, 100], "language": [58, 101, 171], "models": [59], "(LLM).": [60], "To": [61, 177], "examine": [62], "this": [63, 179], "phenomenon,": [64], "we": [65, 125, 157, 181], "present": [66], "MiniGPT-4,": [67, 132], "which": [68, 196], "aligns": [69], "a": [70, 75, 183], "frozen": [71, 76], "visual": [72, 95], "encoder": [73], "with": [74, 97], "advanced": [77, 99, 106], "LLM,": [78], "Vicuna,": [79], "using": [80], "one": [81], "projection": [82], "layer.": [83], "Our": [84, 206], "work,": [85], "for": [86], "first": [88], "time,": [89], "uncovers": [90], "properly": [92], "aligning": [93], "an": [98], "model": [102, 161], "can": [103], "possess": [104], "numerous": [105], "abilities": [108], "by": [110, 139], "GPT-4,": [111], "detailed": [114, 184], "image": [115, 165, 185], "description": [116, 186], "website": [119], "creation": [120], "hand-drawn": [122], "drafts.": [123], "Furthermore,": [124], "also": [126], "observe": [127], "other": [128], "emerging": [129], "including": [133], "writing": [134], "stories": [135], "poems": [137], "inspired": [138], "given": [140], "images,": [141], "teaching": [142], "users": [143], "how": [144], "cook": [146], "based": [147], "on": [148, 163], "food": [149], "photos,": [150], "so": [152], "on.": [153], "In": [154], "our": [155], "experiment,": [156], "found": [158], "trained": [162], "short": [164], "caption": [166], "pairs": [167], "could": [168], "produce": [169], "unnatural": [170], "outputs": [172], "(e.g.,": [173], "repetition": [174], "fragmentation).": [176], "address": [178], "problem,": [180], "curate": [182], "dataset": [187, 212], "second": [190], "stage": [191], "finetune": [193], "model,": [195, 209], "consequently": [197], "improves": [198], "model's": [200], "reliability": [202], "overall": [204], "usability.": [205], "code,": [207], "pre-trained": [208], "collected": [211], "available": [214], "at": [215], "https://minigpt-4.github.io/.": [216]}