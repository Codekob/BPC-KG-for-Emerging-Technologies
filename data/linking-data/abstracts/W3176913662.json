{"We": [0, 43, 122], "present": [1], "a": [2, 15, 22, 31, 106, 168, 184], "generic": [3], "image-to-image": [4, 71, 172], "translation": [5, 72, 126, 173], "framework,": [6], "pixel2style2pixel": [7], "(pSp).": [8], "Our": [9], "pSp": [10], "framework": [11, 166], "is": [12, 115, 138, 201], "based": [13], "on": [14, 167], "novel": [16], "encoder": [17, 48, 67], "network": [18], "that": [19, 46, 124, 190], "directly": [20, 50, 69], "generates": [21], "series": [23], "of": [24, 108, 157, 164, 170], "style": [25], "vectors": [26], "which": [27], "are": [28], "fed": [29], "into": [30, 54, 83], "pretrained": [32], "StyleGAN": [33, 100, 120, 129], "generator,": [34], "forming": [35], "the": [36, 84, 90, 112, 119, 132, 155, 162, 196], "extended": [37, 194], "$\\mathcal{W}": [38, 55], "+": [39, 56], "$": [40], "latent": [41, 85], "space.": [42], "first": [44], "show": [45, 123, 189], "our": [47, 66, 102, 165], "can": [49, 104, 192], "embed": [51], "real": [52], "images": [53], "$,": [57], "with": [58, 98], "no": [59, 136], "additional": [60], "optimization.": [61], "Next,": [62], "we": [63, 160], "propose": [64], "utilizing": [65], "to": [68, 178], "solve": [70], "tasks,": [73, 174], "defining": [74], "them": [75], "as": [76, 135], "encoding": [77], "problems": [78], "from": [79, 89], "some": [80], "input": [81, 113], "domain": [82], "domain.": [86, 121, 199], "By": [87], "deviating": [88], "standard": [91], "\"invert": [92], "first,": [93], "edit": [94], "later\"": [95], "methodology": [96], "used": [97], "previous": [99], "encoders,": [101], "approach": [103], "handle": [105], "variety": [107, 169], "tasks": [109, 127, 145], "even": [110, 175], "when": [111, 176], "image": [114], "not": [116], "represented": [117], "in": [118], "solving": [125, 144], "through": [128], "significantly": [130], "simplifies": [131], "training": [133], "process,": [134], "adversary": [137], "required,": [139], "has": [140], "better": [141], "support": [142], "for": [143, 183], "without": [146], "pixel-to-pixel": [147], "correspondence,": [148], "and": [149, 187], "inherently": [150], "supports": [151], "multi-modal": [152], "synthesis": [153], "via": [154], "resampling": [156], "styles.": [158], "Finally,": [159], "demonstrate": [161], "potential": [163], "facial": [171, 198], "compared": [177], "state-of-the-art": [179], "solutions": [180], "designed": [181], "specifically": [182], "single": [185], "task,": [186], "further": [188], "it": [191], "be": [193], "beyond": [195], "human": [197], "Code": [200], "available": [202], "at": [203], "https://github.com/eladrich/pixel2style2pixel.": [204]}