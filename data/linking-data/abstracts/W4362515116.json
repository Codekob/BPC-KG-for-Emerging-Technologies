{"Language": [0], "is": [1, 186], "essentially": [2], "a": [3, 16, 28, 31, 116, 126, 183], "complex,": [4], "intricate": [5], "system": [6], "of": [7, 165, 189, 201, 234, 253], "human": [8], "expressions": [9], "governed": [10], "by": [11, 67, 100, 177, 236], "grammatical": [12], "rules.": [13], "It": [14], "poses": [15], "significant": [17, 127, 166], "challenge": [18], "to": [19, 55, 91, 105], "develop": [20, 221], "capable": [21], "AI": [22, 212, 224], "algorithms": [23], "for": [24, 40, 162, 270, 278], "comprehending": [25], "and": [26, 43, 180, 182, 222, 242, 260, 273], "grasping": [27], "language.": [29], "As": [30], "major": [32, 251], "approach,": [33], "language": [34, 41, 53, 57, 61, 121, 142, 159], "modeling": [35], "has": [36, 154, 173, 192, 203], "been": [37, 65, 174, 204], "widely": [38], "studied": [39], "understanding": [42], "generation": [44], "in": [45, 77, 140, 148], "the": [46, 97, 102, 112, 146, 151, 156, 163, 169, 187, 210, 217, 231, 238, 267, 275], "past": [47], "two": [48], "decades,": [49], "evolving": [50], "from": [51, 196], "statistical": [52], "models": [54, 62, 70, 122, 160], "neural": [56], "models.": [58, 143], "Recently,": [59, 168], "pre-trained": [60], "(PLMs)": [63], "have": [64, 84], "proposed": [66], "pre-training": [68], "Transformer": [69], "over": [71], "large-scale": [72], "corpora,": [73], "showing": [74], "strong": [75], "capabilities": [76], "solving": [78], "various": [79], "NLP": [80], "tasks.": [81], "Since": [82], "researchers": [83], "found": [85], "that": [86, 136], "model": [87, 103], "scaling": [88, 98], "can": [89], "lead": [90], "performance": [92, 128], "improvement,": [93], "they": [94], "further": [95], "study": [96], "effect": [99], "increasing": [101], "size": [104], "an": [106, 206], "even": [107], "larger": [108], "size.": [109, 167], "Interestingly,": [110], "when": [111], "parameter": [113, 149], "scale": [114], "exceeds": [115], "certain": [117], "level,": [118], "these": [119], "enlarged": [120], "not": [123, 138], "only": [124], "achieve": [125], "improvement": [129], "but": [130], "also": [131, 265], "show": [132], "some": [133], "special": [134], "abilities": [135], "are": [137], "present": [139], "small-scale": [141], "To": [144], "discriminate": [145], "difference": [147], "scale,": [150], "research": [152, 170], "community": [153], "coined": [155], "term": [157], "large": [158], "(LLM)": [161], "PLMs": [164], "on": [171, 209, 249], "LLMs": [172, 202, 235, 272], "largely": [175], "advanced": [176], "both": [178], "academia": [179], "industry,": [181], "remarkable": [184], "progress": [185], "launch": [188], "ChatGPT,": [190], "which": [191, 214], "attracted": [193], "widespread": [194], "attention": [195], "society.": [197], "The": [198], "technical": [199], "evolution": [200], "making": [205], "important": [207], "impact": [208], "entire": [211], "community,": [213], "would": [215], "revolutionize": [216], "way": [218], "how": [219], "we": [220, 229, 247, 264], "use": [223], "algorithms.": [225], "In": [226, 245], "this": [227], "survey,": [228], "review": [230], "recent": [232], "advances": [233], "introducing": [237], "background,": [239], "key": [240], "findings,": [241], "mainstream": [243], "techniques.": [244], "particular,": [246], "focus": [248], "four": [250], "aspects": [252], "LLMs,": [254], "namely": [255], "pre-training,": [256], "adaptation": [257], "tuning,": [258], "utilization,": [259], "capacity": [261], "evaluation.": [262], "Besides,": [263], "summarize": [266], "available": [268], "resources": [269], "developing": [271], "discuss": [274], "remaining": [276], "issues": [277], "future": [279], "directions.": [280]}