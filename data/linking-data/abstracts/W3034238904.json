{"Language": [0], "models": [1], "pretrained": [2, 36], "on": [3], "text": [4], "from": [5], "a": [6, 35, 42, 47, 66, 105], "wide": [7], "variety": [8], "of": [9, 14, 19, 22, 41, 69], "sources": [10], "form": [11], "the": [12, 20, 39, 87], "foundation": [13], "today\u2019s": [15], "NLP.": [16], "In": [17], "light": [18], "success": [21], "these": [23], "broad-coverage": [24], "models,": [25], "we": [26, 100, 128], "investigate": [27], "whether": [28], "it": [29], "is": [30, 114], "still": [31], "helpful": [32], "to": [33, 38, 75, 86, 104], "tailor": [34], "model": [37], "domain": [40], "target": [43], "task.": [44], "We": [45], "present": [46], "study": [48], "across": [49], "four": [50], "domains": [51], "(biomedical": [52], "and": [53, 58, 60, 81], "computer": [54], "science": [55], "publications,": [56], "news,": [57], "reviews)": [59], "eight": [61], "classification": [62], "tasks,": [63], "showing": [64], "that": [65, 102, 131], "second": [67], "phase": [68], "pretraining": [70, 123, 134], "in-domain": [71], "(domain-adaptive": [72], "pretraining)": [73, 92], "leads": [74], "performance": [76, 94], "gains,": [77], "under": [78], "both": [79], "high-": [80], "low-resource": [82], "settings.": [83], "Moreover,": [84], "adapting": [85, 103], "task\u2019s": [88], "unlabeled": [89], "data": [90, 111], "(task-adaptive": [91], "improves": [93], "even": [95], "after": [96], "domain-adaptive": [97, 122], "pretraining.": [98], "Finally,": [99], "show": [101], "task": [106, 139], "corpus": [107], "augmented": [108], "using": [109], "simple": [110], "selection": [112], "strategies": [113], "an": [115], "effective": [116], "alternative,": [117], "especially": [118], "when": [119], "resources": [120], "for": [121], "might": [124], "be": [125], "unavailable.": [126], "Overall,": [127], "consistently": [129], "find": [130], "multi-phase": [132], "adaptive": [133], "offers": [135], "large": [136], "gains": [137], "in": [138], "performance.": [140]}