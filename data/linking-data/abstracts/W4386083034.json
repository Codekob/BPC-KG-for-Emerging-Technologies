{"Transformer-based": [0], "methods": [1, 171], "have": [2], "shown": [3], "impressive": [4], "performance": [5, 156], "in": [6, 45], "low-level": [7], "vision": [8], "tasks,": [9], "such": [10], "as": [11], "image": [12], "super-resolution.": [13], "However,": [14], "we": [15, 58, 101, 119, 146], "find": [16], "that": [17, 35, 154], "these": [18], "networks": [19], "can": [20, 160], "only": [21], "utilize": [22, 86], "a": [23, 60, 122], "limited": [24], "spatial": [25], "range": [26], "of": [27, 38, 78, 82, 130, 141, 157], "input": [28, 53], "information": [29], "through": [30], "attribution": [31], "analysis.": [32], "This": [33], "implies": [34], "the": [36, 98, 109, 116, 128, 131, 139, 142, 150, 155, 169], "potential": [37, 129], "Transformer": [39, 64], "is": [40], "still": [41], "not": [42], "fully": [43], "exploited": [44], "existing": [46], "networks.": [47], "In": [48, 115], "order": [49], "to": [50, 85, 95, 107, 126, 152], "activate": [51], "more": [52, 173], "pixels": [54], "for": [55, 133], "better": [56, 96], "reconstruction,": [57], "propose": [59], "novel": [61], "Hybrid": [62], "Attention": [63], "(HAT).": [65], "It": [66], "combines": [67], "both": [68], "channel": [69], "attention": [70], "and": [71, 89, 145], "window-based": [72], "self-attention": [73], "schemes,": [74], "thus": [75], "making": [76], "use": [77], "their": [79], "complementary": [80], "advantages": [81], "being": [83], "able": [84], "global": [87], "statistics": [88], "strong": [90], "local": [91], "fitting": [92], "capability.": [93], "Moreover,": [94], "aggregate": [97], "cross-window": [99], "information,": [100], "introduce": [102], "an": [103], "overlapping": [104], "cross-attention": [105], "module": [106], "enhance": [108], "interaction": [110], "between": [111], "neighboring": [112], "window": [113], "features.": [114], "training": [117], "stage,": [118], "additionally": [120], "adopt": [121], "same-task": [123], "pre-training": [124], "strategy": [125], "exploit": [127], "model": [132, 151], "further": [134, 147], "improvement.": [135], "Extensive": [136], "experiments": [137], "show": [138], "effectiveness": [140], "proposed": [143], "modules,": [144], "scale": [148], "up": [149], "demonstrate": [153], "this": [158], "task": [159], "be": [161], "greatly": [162], "improved.": [163], "Our": [164], "overall": [165], "method": [166], "significantly": [167], "outperforms": [168], "state-of-the-art": [170], "by": [172], "than": [174], "1dB.": [175]}