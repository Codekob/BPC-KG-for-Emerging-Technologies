{"Recently,": [0], "channel": [1, 73, 88], "attention": [2, 29, 74], "mechanism": [3], "has": [4], "demonstrated": [5], "to": [6, 25, 126], "offer": [7], "great": [8], "potential": [9], "in": [10, 76, 180], "improving": [11], "the": [12, 42, 72, 150, 173], "performance": [13, 45, 68, 96, 174], "of": [14, 44, 63, 131, 136, 154, 159, 182, 201], "deep": [15], "convolutional": [16], "neural": [17], "networks": [18], "(CNNs).": [19], "However,": [20], "most": [21], "existing": [22], "methods": [23], "dedicate": [24], "developing": [26], "more": [27, 177, 212], "sophisticated": [28], "modules": [30, 156], "for": [31, 86], "achieving": [32], "better": [33], "performance,": [34], "which": [35, 58, 113], "inevitably": [36], "increase": [37], "model": [38, 100], "complexity.": [39, 101], "To": [40], "overcome": [41], "paradox": [43], "and": [46, 90, 147, 152, 165, 172, 196, 203], "complexity": [47], "trade-off,": [48], "this": [49], "paper": [50], "proposes": [51], "an": [52], "Efficient": [53], "Channel": [54], "Attention": [55], "(ECA)": [56], "module,": [57], "only": [59], "involves": [60], "a": [61, 105, 124], "handful": [62], "parameters": [64, 151], "while": [65, 97, 214], "bringing": [66], "clear": [67], "gain.": [69], "By": [70], "dissecting": [71], "module": [75, 143, 190, 210], "SENet,": [77], "we": [78, 103, 122], "empirically": [79], "show": [80, 208], "avoiding": [81], "dimensionality": [82, 111], "reduction": [83], "is": [84, 144, 176, 211], "important": [85], "learning": [87], "attention,": [89], "appropriate": [91], "cross-channel": [92, 107, 138], "interaction": [93, 108], "can": [94, 114], "preserve": [95], "significantly": [98], "decreasing": [99], "Therefore,": [102], "propose": [104], "local": [106, 137], "strategy": [109], "without": [110], "reduction,": [112], "be": [115], "efficiently": [116], "implemented": [117], "via": [118], "1D": [119, 132], "convolution.": [120], "Furthermore,": [121], "develop": [123], "method": [125], "adaptively": [127], "select": [128], "kernel": [129], "size": [130], "convolution,": [133], "determining": [134], "coverage": [135], "interaction.": [139], "The": [140, 205], "proposed": [141], "ECA": [142, 189], "both": [145], "efficient": [146, 213], "effective,": [148], "e.g.,": [149], "computations": [153], "our": [155, 188, 209], "against": [157, 217], "backbone": [158], "ResNet50": [160], "are": [161], "80": [162], "vs.": [163, 168], "24.37M": [164], "4.7e-4": [166], "GFlops": [167], "3.86": [169], "GFlops,": [170], "respectively,": [171], "boost": [175], "than": [178], "2%": [179], "terms": [181], "Top-1": [183], "accuracy.": [184], "We": [185], "extensively": [186], "evaluate": [187], "on": [191], "image": [192], "classification,": [193], "object": [194], "detection": [195], "instance": [197], "segmentation": [198], "with": [199], "backbones": [200], "ResNets": [202], "MobileNetV2.": [204], "experimental": [206], "results": [207], "performing": [215], "favorably": [216], "its": [218], "counterparts.": [219]}