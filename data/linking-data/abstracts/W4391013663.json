{"Recently": [0], "the": [1, 11, 48, 54, 68, 93, 101, 176, 195], "state": [2, 106], "space": [3, 107], "models": [4], "(SSMs)": [5], "with": [6, 86, 96, 104, 162], "efficient": [7, 26], "hardware-aware": [8], "designs,": [9], "i.e.,": [10], "Mamba": [12, 88], "deep": [13], "learning": [14, 75], "model,": [15], "have": [16], "shown": [17], "great": [18, 191], "potential": [19, 192], "for": [20, 44, 59, 72, 185, 198], "long": [21], "sequence": [22], "modeling.": [23], "Meanwhile": [24], "building": [25], "and": [27, 53, 79, 99, 115, 148, 188], "generic": [28, 83], "vision": [29, 84, 127, 199], "backbones": [30], "purely": [31], "upon": [32], "SSMs": [33, 45], "is": [34, 42, 76, 143, 172, 203], "an": [35], "appealing": [36], "direction.": [37], "However,": [38], "representing": [39], "visual": [40, 51, 60, 73, 102], "data": [41, 52], "challenging": [43], "due": [46], "to": [47, 125, 157, 193], "position-sensitivity": [49], "of": [50, 56, 165, 174], "requirement": [55], "global": [57], "context": [58], "understanding.": [61], "In": [62], "this": [63], "paper,": [64], "we": [65], "show": [66], "that": [67, 170], "reliance": [69], "on": [70, 160, 181], "self-attention": [71], "representation": [74, 103], "not": [77], "necessary": [78], "propose": [80], "a": [81, 163], "new": [82], "backbone": [85, 197], "bidirectional": [87, 105], "blocks": [89], "(Vim),": [90], "which": [91], "marks": [92], "image": [94], "sequences": [95], "position": [97], "embeddings": [98], "compresses": [100], "models.": [108, 201], "On": [109], "ImageNet": [110], "classification,": [111], "COCO": [112], "object": [113], "detection,": [114], "ADE20k": [116], "semantic": [117], "segmentation": [118], "tasks,": [119], "Vim": [120, 142, 171], "achieves": [121], "higher": [122], "performance": [123], "compared": [124], "well-established": [126], "transformers": [128], "like": [129], "DeiT,": [130], "while": [131], "also": [132], "demonstrating": [133], "significantly": [134], "improved": [135], "computation": [136, 177], "&": [137, 178], "memory": [138, 152, 179], "efficiency.": [139], "For": [140], "example,": [141], "2.8$\\times$": [144], "faster": [145], "than": [146], "DeiT": [147], "saves": [149], "86.8%": [150], "GPU": [151], "when": [153], "performing": [154, 182], "batch": [155], "inference": [156], "extract": [158], "features": [159], "images": [161, 187], "resolution": [164], "1248$\\times$1248.": [166], "The": [167], "results": [168], "demonstrate": [169], "capable": [173], "overcoming": [175], "constraints": [180], "Transformer-style": [183], "understanding": [184], "high-resolution": [186], "it": [189], "has": [190], "be": [194], "next-generation": [196], "foundation": [200], "Code": [202], "available": [204], "at": [205], "https://github.com/hustvl/Vim.": [206]}