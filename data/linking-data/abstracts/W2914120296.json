{"Recent": [0], "studies": [1], "have": [2], "demonstrated": [3], "the": [4, 26, 80, 83, 104, 108, 125, 134], "efficiency": [5], "of": [6, 28, 82, 89, 107, 124, 127], "generative": [7], "pretraining": [8], "for": [9], "English": [10], "natural": [11], "language": [12, 38, 60], "understanding.": [13], "In": [14], "this": [15, 19], "work,": [16], "we": [17, 96, 119], "extend": [18], "approach": [20, 78, 137], "to": [21, 35], "multiple": [22], "languages": [23], "and": [24, 49, 71, 145], "show": [25], "effectiveness": [27], "cross-lingual": [29, 37, 59, 68], "pretraining.": [30], "We": [31, 63], "propose": [32], "two": [33], "methods": [34], "learn": [36], "models": [39, 147], "(XLMs):": [40], "one": [41, 50], "unsupervised": [42, 70, 93], "that": [43, 52], "only": [44], "relies": [45], "on": [46, 67, 100, 130], "monolingual": [47], "data,": [48], "supervised": [51, 72, 116], "leverages": [53], "parallel": [54], "data": [55], "with": [56], "a": [57, 121], "new": [58, 122], "model": [61], "objective.": [62], "obtain": [64, 97, 120], "state-of-the-art": [65], "results": [66], "classification,": [69], "machine": [73, 94, 117], "translation.": [74], "On": [75, 92, 115], "XNLI,": [76], "our": [77], "pushes": [79], "state": [81, 106, 123], "art": [84, 109, 126], "by": [85, 110, 138], "an": [86], "absolute": [87], "gain": [88], "4.9%": [90], "accuracy.": [91], "translation,": [95, 118], "34.3": [98], "BLEU": [99, 129], "WMT'16": [101, 131], "German-English,": [102], "improving": [103], "previous": [105, 135], "more": [111, 139], "than": [112, 140], "9": [113], "BLEU.": [114, 142], "38.5": [128], "Romanian-English,": [132], "outperforming": [133], "best": [136], "4": [141], "Our": [143], "code": [144], "pretrained": [146], "will": [148], "be": [149], "made": [150], "publicly": [151], "available.": [152]}